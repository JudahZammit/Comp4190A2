{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "all_files = glob.glob('*.csv')\n",
    "\n",
    "temp = []\n",
    "for filename in all_files:\n",
    "    df = pd.concat((pd.read_csv(f) for f in all_files))\n",
    "    temp.append(df)\n",
    "frame = pd.concat(temp, axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = frame.drop('No', 1)\n",
    "#Drops all rows with a NaN value\n",
    "frame = frame.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalize data\n",
    "\n",
    "#These are all the columns that are numeric\n",
    "numeric_col = ['SO2','NO2','CO','O3','TEMP','PRES','DEWP','RAIN','WSPM']\n",
    "\n",
    "for col in numeric_col:\n",
    "    frame[col] = (frame[col] - frame[col].min())/(frame[col].max() - frame[col].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#fetch train-data and test_data\n",
    "train_data=frame.loc[frame['year']!=2017 ]\n",
    "test_data=frame.loc[frame['year']==2017]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>PM2.5</th>\n",
       "      <th>PM10</th>\n",
       "      <th>SO2</th>\n",
       "      <th>NO2</th>\n",
       "      <th>CO</th>\n",
       "      <th>O3</th>\n",
       "      <th>TEMP</th>\n",
       "      <th>PRES</th>\n",
       "      <th>DEWP</th>\n",
       "      <th>RAIN</th>\n",
       "      <th>wd</th>\n",
       "      <th>WSPM</th>\n",
       "      <th>station</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.011435</td>\n",
       "      <td>0.052083</td>\n",
       "      <td>0.010101</td>\n",
       "      <td>0.057701</td>\n",
       "      <td>0.328455</td>\n",
       "      <td>0.653974</td>\n",
       "      <td>0.261137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>WNW</td>\n",
       "      <td>0.151515</td>\n",
       "      <td>Wanshouxigong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.013436</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.010101</td>\n",
       "      <td>0.061437</td>\n",
       "      <td>0.321951</td>\n",
       "      <td>0.662252</td>\n",
       "      <td>0.256528</td>\n",
       "      <td>0.0</td>\n",
       "      <td>WNW</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>Wanshouxigong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.007433</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>0.010101</td>\n",
       "      <td>0.059569</td>\n",
       "      <td>0.297561</td>\n",
       "      <td>0.700331</td>\n",
       "      <td>0.228879</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NE</td>\n",
       "      <td>0.151515</td>\n",
       "      <td>Wanshouxigong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.011435</td>\n",
       "      <td>0.038194</td>\n",
       "      <td>0.020202</td>\n",
       "      <td>0.056767</td>\n",
       "      <td>0.284553</td>\n",
       "      <td>0.711921</td>\n",
       "      <td>0.241167</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NE</td>\n",
       "      <td>0.174242</td>\n",
       "      <td>Wanshouxigong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.015438</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.020202</td>\n",
       "      <td>0.050230</td>\n",
       "      <td>0.310569</td>\n",
       "      <td>0.733444</td>\n",
       "      <td>0.247312</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NNE</td>\n",
       "      <td>0.151515</td>\n",
       "      <td>Wanshouxigong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5049211</th>\n",
       "      <td>2017</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>19</td>\n",
       "      <td>13.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.005432</td>\n",
       "      <td>0.118056</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.055834</td>\n",
       "      <td>0.526829</td>\n",
       "      <td>0.514901</td>\n",
       "      <td>0.304147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>Guanyuan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5049212</th>\n",
       "      <td>2017</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>20</td>\n",
       "      <td>20.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.007433</td>\n",
       "      <td>0.159722</td>\n",
       "      <td>0.040404</td>\n",
       "      <td>0.039957</td>\n",
       "      <td>0.512195</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.321045</td>\n",
       "      <td>0.0</td>\n",
       "      <td>WNW</td>\n",
       "      <td>0.068182</td>\n",
       "      <td>Guanyuan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5049213</th>\n",
       "      <td>2017</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>21</td>\n",
       "      <td>16.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.009434</td>\n",
       "      <td>0.128472</td>\n",
       "      <td>0.040404</td>\n",
       "      <td>0.046495</td>\n",
       "      <td>0.499187</td>\n",
       "      <td>0.526490</td>\n",
       "      <td>0.348694</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>Guanyuan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5049214</th>\n",
       "      <td>2017</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>22</td>\n",
       "      <td>11.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.009434</td>\n",
       "      <td>0.156250</td>\n",
       "      <td>0.040404</td>\n",
       "      <td>0.038090</td>\n",
       "      <td>0.494309</td>\n",
       "      <td>0.529801</td>\n",
       "      <td>0.354839</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NNW</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>Guanyuan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5049215</th>\n",
       "      <td>2017</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>23</td>\n",
       "      <td>15.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.009434</td>\n",
       "      <td>0.177083</td>\n",
       "      <td>0.050505</td>\n",
       "      <td>0.030618</td>\n",
       "      <td>0.463415</td>\n",
       "      <td>0.524834</td>\n",
       "      <td>0.308756</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NNE</td>\n",
       "      <td>0.098485</td>\n",
       "      <td>Guanyuan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4586016 rows Ã— 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         year  month  day  hour  PM2.5  PM10       SO2       NO2        CO  \\\n",
       "0        2013      3    1     0    9.0   9.0  0.011435  0.052083  0.010101   \n",
       "1        2013      3    1     1   11.0  11.0  0.013436  0.041667  0.010101   \n",
       "5        2013      3    1     5   10.0  10.0  0.007433  0.020833  0.010101   \n",
       "6        2013      3    1     6    8.0   8.0  0.011435  0.038194  0.020202   \n",
       "7        2013      3    1     7    8.0   8.0  0.015438  0.062500  0.020202   \n",
       "...       ...    ...  ...   ...    ...   ...       ...       ...       ...   \n",
       "5049211  2017      2   28    19   13.0  37.0  0.005432  0.118056  0.030303   \n",
       "5049212  2017      2   28    20   20.0  43.0  0.007433  0.159722  0.040404   \n",
       "5049213  2017      2   28    21   16.0  33.0  0.009434  0.128472  0.040404   \n",
       "5049214  2017      2   28    22   11.0  24.0  0.009434  0.156250  0.040404   \n",
       "5049215  2017      2   28    23   15.0  27.0  0.009434  0.177083  0.050505   \n",
       "\n",
       "               O3      TEMP      PRES      DEWP  RAIN   wd      WSPM  \\\n",
       "0        0.057701  0.328455  0.653974  0.261137   0.0  WNW  0.151515   \n",
       "1        0.061437  0.321951  0.662252  0.256528   0.0  WNW  0.333333   \n",
       "5        0.059569  0.297561  0.700331  0.228879   0.0   NE  0.151515   \n",
       "6        0.056767  0.284553  0.711921  0.241167   0.0   NE  0.174242   \n",
       "7        0.050230  0.310569  0.733444  0.247312   0.0  NNE  0.151515   \n",
       "...           ...       ...       ...       ...   ...  ...       ...   \n",
       "5049211  0.055834  0.526829  0.514901  0.304147   0.0   NW  0.181818   \n",
       "5049212  0.039957  0.512195  0.516556  0.321045   0.0  WNW  0.068182   \n",
       "5049213  0.046495  0.499187  0.526490  0.348694   0.0   NW  0.083333   \n",
       "5049214  0.038090  0.494309  0.529801  0.354839   0.0  NNW  0.090909   \n",
       "5049215  0.030618  0.463415  0.524834  0.308756   0.0  NNE  0.098485   \n",
       "\n",
       "               station  \n",
       "0        Wanshouxigong  \n",
       "1        Wanshouxigong  \n",
       "5        Wanshouxigong  \n",
       "6        Wanshouxigong  \n",
       "7        Wanshouxigong  \n",
       "...                ...  \n",
       "5049211       Guanyuan  \n",
       "5049212       Guanyuan  \n",
       "5049213       Guanyuan  \n",
       "5049214       Guanyuan  \n",
       "5049215       Guanyuan  \n",
       "\n",
       "[4586016 rows x 17 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y_train=np.array(train_data['PM2.5'].values)\n",
    "y_test=np.array(test_data['PM2.5'].values)\n",
    "\n",
    "#multidimentional data\n",
    "x_train=np.array(train_data[['TEMP', 'PRES', 'DEWP', 'RAIN', 'wd', 'WSPM']].values)\n",
    "x_test=np.array(test_data[['TEMP', 'PRES', 'DEWP', 'RAIN', 'wd', 'WSPM']].values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, dim=1):\n",
    "        super(Linear, self).__init__()\n",
    "        self.w = tf.Variable(initial_value=tf.zeros((dim)),\n",
    "                             trainable=True)\n",
    "\n",
    "        self.b = tf.Variable(initial_value=tf.zeros((1)),\n",
    "                             trainable=True)\n",
    "        self.dim = dim\n",
    "\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = inputs\n",
    "        \n",
    "        #x must be the right size\n",
    "        assert(x.shape[1] == self.dim)\n",
    "        \n",
    "        out = (self.w*x) + self.b\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_col = ['TEMP', 'PRES', 'DEWP', 'RAIN', 'WSPM']\n",
    "\n",
    "train_data[train_col].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4394460 samples, validate on 191556 samples\n",
      "Epoch 1/200\n",
      "4394460/4394460 [==============================] - 8s 2us/sample - loss: 11961.7502 - val_loss: 19388.5285\n",
      "Epoch 2/200\n",
      "4394460/4394460 [==============================] - 6s 1us/sample - loss: 11133.7715 - val_loss: 18491.9669\n",
      "Epoch 3/200\n",
      "4394460/4394460 [==============================] - 5s 1us/sample - loss: 10376.3735 - val_loss: 17658.8925\n",
      "Epoch 4/200\n",
      "4394460/4394460 [==============================] - 6s 1us/sample - loss: 9687.6232 - val_loss: 16888.5305\n",
      "Epoch 5/200\n",
      "4394460/4394460 [==============================] - 6s 1us/sample - loss: 9067.0583 - val_loss: 16180.9847\n",
      "Epoch 6/200\n",
      "4394460/4394460 [==============================] - 6s 1us/sample - loss: 8514.5792 - val_loss: 15535.8724\n",
      "Epoch 7/200\n",
      "4394460/4394460 [==============================] - 6s 1us/sample - loss: 8030.0773 - val_loss: 14953.8019\n",
      "Epoch 8/200\n",
      "4394460/4394460 [==============================] - 6s 1us/sample - loss: 7612.9225 - val_loss: 14433.9759\n",
      "Epoch 9/200\n",
      "4394460/4394460 [==============================] - 6s 1us/sample - loss: 7263.0668 - val_loss: 13977.0323\n",
      "Epoch 10/200\n",
      "4394460/4394460 [==============================] - 6s 1us/sample - loss: 6979.3957 - val_loss: 13582.6340\n",
      "Epoch 11/200\n",
      "4394460/4394460 [==============================] - 6s 1us/sample - loss: 6760.9459 - val_loss: 13252.5345\n",
      "Epoch 12/200\n",
      "4394460/4394460 [==============================] - 6s 1us/sample - loss: 6604.2431 - val_loss: 12994.5483\n",
      "Epoch 13/200\n",
      "4394460/4394460 [==============================] - 6s 1us/sample - loss: 6497.0556 - val_loss: 12814.1826\n",
      "Epoch 14/200\n",
      "4394460/4394460 [==============================] - 7s 1us/sample - loss: 6419.1625 - val_loss: 12672.3366\n",
      "Epoch 15/200\n",
      "4394460/4394460 [==============================] - 6s 1us/sample - loss: 6359.0713 - val_loss: 12556.0304\n",
      "Epoch 16/200\n",
      "4394460/4394460 [==============================] - 6s 1us/sample - loss: 6313.7096 - val_loss: 12465.4927\n",
      "Epoch 17/200\n",
      "4394460/4394460 [==============================] - 6s 1us/sample - loss: 6280.8731 - val_loss: 12402.3115\n",
      "Epoch 18/200\n",
      "4394460/4394460 [==============================] - 7s 2us/sample - loss: 6256.6812 - val_loss: 12363.8857\n",
      "Epoch 19/200\n",
      "4394460/4394460 [==============================] - 7s 2us/sample - loss: 6237.5266 - val_loss: 12337.2109\n",
      "Epoch 20/200\n",
      "4394460/4394460 [==============================] - 6s 1us/sample - loss: 6221.6541 - val_loss: 12314.9051\n",
      "Epoch 21/200\n",
      "4394460/4394460 [==============================] - 6s 1us/sample - loss: 6208.4316 - val_loss: 12294.1353\n",
      "Epoch 22/200\n",
      "4394460/4394460 [==============================] - 7s 2us/sample - loss: 6197.5665 - val_loss: 12277.0933\n",
      "Epoch 23/200\n",
      "4394460/4394460 [==============================] - 6s 1us/sample - loss: 6188.8195 - val_loss: 12259.8563\n",
      "Epoch 24/200\n",
      "4394460/4394460 [==============================] - 6s 1us/sample - loss: 6181.6972 - val_loss: 12244.9912\n",
      "Epoch 25/200\n",
      "4394460/4394460 [==============================] - 7s 1us/sample - loss: 6175.8677 - val_loss: 12231.7771\n",
      "Epoch 26/200\n",
      "4394460/4394460 [==============================] - 6s 1us/sample - loss: 6171.0235 - val_loss: 12220.5279\n",
      "Epoch 27/200\n",
      "4394460/4394460 [==============================] - 6s 1us/sample - loss: 6166.8792 - val_loss: 12211.1774\n",
      "Epoch 28/200\n",
      "4394460/4394460 [==============================] - 6s 1us/sample - loss: 6163.2273 - val_loss: 12201.9446\n",
      "Epoch 29/200\n",
      "4394460/4394460 [==============================] - 5s 1us/sample - loss: 6159.9211 - val_loss: 12192.3030\n",
      "Epoch 30/200\n",
      "4394460/4394460 [==============================] - 5s 1us/sample - loss: 6156.8790 - val_loss: 12185.4658\n",
      "Epoch 31/200\n",
      "4394460/4394460 [==============================] - 5s 1us/sample - loss: 6154.0602 - val_loss: 12177.6642\n",
      "Epoch 32/200\n",
      "4394460/4394460 [==============================] - 5s 1us/sample - loss: 6151.4095 - val_loss: 12170.4440\n",
      "Epoch 33/200\n",
      "4394460/4394460 [==============================] - 5s 1us/sample - loss: 6148.9237 - val_loss: 12164.2640\n",
      "Epoch 34/200\n",
      "4394460/4394460 [==============================] - 5s 1us/sample - loss: 6146.5896 - val_loss: 12158.2402\n",
      "Epoch 35/200\n",
      "4394460/4394460 [==============================] - 5s 1us/sample - loss: 6144.4023 - val_loss: 12151.1297\n",
      "Epoch 36/200\n",
      "4394460/4394460 [==============================] - 6s 1us/sample - loss: 6142.3574 - val_loss: 12145.7325\n",
      "Epoch 37/200\n",
      "4394460/4394460 [==============================] - 6s 1us/sample - loss: 6140.4456 - val_loss: 12141.3042\n",
      "Epoch 38/200\n",
      "4394460/4394460 [==============================] - 8s 2us/sample - loss: 6138.6693 - val_loss: 12135.3307\n",
      "Epoch 39/200\n",
      " 502784/4394460 [==>...........................] - ETA: 8s - loss: 6155.3929 - ETA: 11s - loss: "
     ]
    }
   ],
   "source": [
    "train_col = ['TEMP', 'PRES', 'DEWP', 'RAIN', 'WSPM']\n",
    "\n",
    "x_train = train_data[train_col].to_numpy()\n",
    "y_train = train_data['PM2.5'].to_numpy()\n",
    "x_test = test_data[train_col].to_numpy()\n",
    "y_test = test_data['PM2.5'].to_numpy()\n",
    "\n",
    "model = Linear(dim = len(train_col))\n",
    "model.compile('adam','mse')\n",
    "model.fit(x = x_train ,y = y_train,epochs = 200\n",
    "          ,batch_size = 1024,validation_data = (x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# represent the wind's direction as a number (radius)\n",
    "#this method receives a set and change everything to a number\n",
    "def getWindAngle(Z):\n",
    "    Y=[]\n",
    "    for direct in Z:\n",
    "        if pd.isnull(direct):\n",
    "            Y.append(math.nan)\n",
    "        elif direct =='SW':\n",
    "            Y.append(np.radians(225))\n",
    "        elif direct =='N':\n",
    "            Y.append(np.radians(0))\n",
    "        elif direct =='NNW':\n",
    "            Y.append(np.radians(337.5))\n",
    "        elif direct =='WNW':\n",
    "            Y.append(np.radians(292.5))\n",
    "        elif direct =='WSW':\n",
    "            Y.append(np.radians(247.5))\n",
    "        elif direct =='E':\n",
    "            Y.append(np.radians(90))\n",
    "        elif direct =='NE':\n",
    "            Y.append(np.radians(45))\n",
    "        elif direct =='ENE':\n",
    "            Y.append(np.radians(67.5))\n",
    "        elif direct =='ESE':\n",
    "            Y.append(np.radians(112.5))\n",
    "        elif direct =='S':\n",
    "            Y.append(np.radians(180))\n",
    "        elif direct =='SE':\n",
    "            Y.append(np.radians(135))\n",
    "        elif direct =='SSE':\n",
    "            Y.append(np.radians(157.5))\n",
    "        elif direct =='SSW':\n",
    "            Y.append(np.radians(202.5))\n",
    "        elif direct =='NNE':\n",
    "            Y.append(np.radians(22.5))\n",
    "        elif direct =='NW':\n",
    "            Y.append(np.radians(315.5))\n",
    "        elif direct =='W':\n",
    "            Y.append(np.radians(270))\n",
    "        \n",
    "    return np.array(Y)\n",
    "        \n",
    "            \n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_simple_wind(eta,epochs):\n",
    "    # this step removes all nans in wind and y then change the string in wd to numbers\n",
    "    global x_train_wd,y_train,x_test_wd,y_test\n",
    "    wd_new,y_new=removeNan_str(x_train_wd,y_train)\n",
    "   \n",
    "    wd_test,y_test=removeNan_str(x_test_wd,y_test)\n",
    "    wd_test,y_test=wd_test[:min(wd_test.shape[0],y_test.shape[0])],y_test[:min(wd_test.shape[0],y_test.shape[0])]\n",
    "    wd_new=getWindAngle(wd_new)\n",
    "    wd_test=getWindAngle(wd_test)\n",
    "    x,y,pred=train_simple(wd_new,y_new,wd_test,y_test,eta,epochs)\n",
    "    plt.scatter(wd_test,y_test,c='r',s=0.01)\n",
    "    plt.plot(wd_test,pred,c='g')\n",
    "    plt.yscale('linear')\n",
    "    plt.show()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this part is for part one except wind\n",
    "plot_simple(x_train_TEMP,y_train,x_test_TEMP,y_test,0.0028,1550)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# this part is for part 1 wind\n",
    "plot_simple_wind(0.005,500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " print(x_test_wd.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#preprocess the training matrix and its label so that it contains no nan's \n",
    "#then replace the str angle with numerical one\n",
    "a=set(np.argwhere(pd.isnull(x_train))[:,0])\n",
    "b=set(np.argwhere(pd.isnull(y_train))[:,0])\n",
    "indices=list(a.union(b))\n",
    "x_newTrain=np.delete(x_train,indices,axis=0)\n",
    "y_newTrain=np.delete(y_train,indices,axis=0)\n",
    "angles=getWindAngle(x_newTrain[:,4])\n",
    "x_newTrain[:,4]=angles\n",
    "print(x_newTrain)\n",
    "print(pd.isnull(x_newTrain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#do that same thing for test data\n",
    "x_test1=x_test[:min(x_test.shape[0],y_test.shape[0]),:]\n",
    "y_test1=y_test[:min(x_test.shape[0],y_test.shape[0])]\n",
    "c=set(np.argwhere(pd.isnull(x_test1))[:,0])\n",
    "d=set(np.argwhere(pd.isnull(y_test1))[:,0])\n",
    "indices=list(c.union(d))\n",
    "x_newTest=np.delete(x_test1,indices,axis=0)\n",
    "y_newTest=np.delete(y_test1,indices,axis=0)\n",
    "angles1=getWindAngle(x_newTest[:,4])\n",
    "x_newTest[:,4]=angles1\n",
    "print(x_newTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#this method is to give a model(multidimensional)\n",
    "def train_multiple(X,Y,X_test,Y_test,eta,epochs):\n",
    "    original=0     #the original weight^2+bias^2\n",
    "    #set placeholders and variables\n",
    "    x=tf.placeholder(dtype=tf.float32)\n",
    "    y=tf.placeholder(dtype=tf.float32)\n",
    "    weight=tf.Variable(np.random.normal(size=(6,1)))\n",
    "    bias=tf.Variable(np.random.normal())\n",
    "    #the prediction with the current model\n",
    "    bias=tf.cast(bias,tf.float32)\n",
    "    weight=tf.cast(weight,tf.float32)\n",
    "    result=tf.add(tf.matmul(x,weight),bias)\n",
    "    loss=tf.reduce_mean(tf.square(result-y))\n",
    "    optimizer=tf.train.AdamOptimizer(learning_rate=eta).minimize(loss)  #can choose adam if you want\n",
    "    feed_dict={x:X,y:Y}\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        for epoch in range(epochs):\n",
    "            sess.run(optimizer,feed_dict=feed_dict)\n",
    "            if(epoch%20==0):\n",
    "                print('cost:{}'.format(sess.run(loss,feed_dict=feed_dict)))\n",
    "                print('w:{}'.format(weight.eval()))\n",
    "                print('b:{}'.format(bias.eval()))\n",
    "                print()\n",
    "        print('the final result:')\n",
    "        print(weight.eval())\n",
    "        print(bias.eval())\n",
    "        print('start testing:')\n",
    "        prediction=sess.run(result,feed_dict={x:X_test})\n",
    "        return X_test,Y_test,prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this method is to give a model(multidimensional)\n",
    "def train_multiple_SGD(X,Y,X_test,Y_test,eta,epochs,size):\n",
    "    original=0     #the original weight^2+bias^2\n",
    "    #set placeholders and variables\n",
    "    x=tf.placeholder(dtype=tf.float32)\n",
    "    y=tf.placeholder(dtype=tf.float32)\n",
    "    weight=tf.Variable(np.random.normal(size=(6,1)))\n",
    "    bias=tf.Variable(np.random.normal())\n",
    "    #the prediction with the current model\n",
    "    bias=tf.cast(bias,tf.float32)\n",
    "    weight=tf.cast(weight,tf.float32)\n",
    "    result=tf.add(tf.matmul(x,weight),bias)\n",
    "    loss=tf.reduce_mean(tf.square(result-y))\n",
    "    optimizer=tf.train.AdamOptimizer(learning_rate=eta).minimize(loss)  #can choose adam if you want\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        for epoch in range(epochs):\n",
    "            start=time.time()\n",
    "            indices=np.random.choice(range(X.shape[0]), size, replace=False)\n",
    "            feed_dict={x:X[indices],y:Y[indices]}\n",
    "            sess.run(optimizer,feed_dict=feed_dict)\n",
    "            print('time spent on this epoch:{}'.format(time.time()-start))\n",
    "            if(epoch%20==0):\n",
    "                print('cost:{}'.format(sess.run(loss,feed_dict=feed_dict)))\n",
    "                print('w:{}'.format(weight.eval()))\n",
    "                print('b:{}'.format(bias.eval()))\n",
    "                print()\n",
    "        print('the final result:')\n",
    "        print(weight.eval())\n",
    "        print(bias.eval())\n",
    "        print('start testing:')\n",
    "        prediction=sess.run(result,feed_dict={x:X_test}).T[0]\n",
    "        return X_test,Y_test,prediction,weight.eval().T[0],bias.eval()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if you set the size to be the original one, your runnin out of memory\n",
    "#so this way is not efficient, we have to use the stochastic one\n",
    "size=int(x_newTrain.shape[0]/500)\n",
    "train_multiple(x_newTrain[:size],y_newTrain[:size],x_newTest,y_newTest,0.0039,500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#test of sgd \n",
    "#we gotta choose the best size for stochastic gradient descent\n",
    "size=int((x_newTrain.shape[0])/1500)\n",
    "x_t,y_t,pred,w,b=train_multiple_SGD(x_newTrain,y_newTrain,x_newTest,y_newTest,0.03,100,size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "np.mean(abs(np.dot(np.array(x_newTrain,dtype='float32'),w)+b-y_newTrain)/np.dot(np.array(x_newTrain,dtype='float32'),w)+b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_newTest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
